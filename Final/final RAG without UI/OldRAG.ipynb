{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pinecone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWXjtNdU_TDO",
        "outputId": "faa50e64-a63e-4828-dacb-dd69bff872dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pinecone\n",
            "  Downloading pinecone-6.0.2-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2025.1.31)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Downloading pinecone-6.0.2-py3-none-any.whl (421 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.9/421.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Installing collected packages: pinecone-plugin-interface, pinecone\n",
            "Successfully installed pinecone-6.0.2 pinecone-plugin-interface-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube_transcript_api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmCWvuYvO2k3",
        "outputId": "d92f2985-08e1-446a-a158-e1f6dbb62c42"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube_transcript_api\n",
            "  Downloading youtube_transcript_api-1.0.3-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (2025.1.31)\n",
            "Downloading youtube_transcript_api-1.0.3-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: youtube_transcript_api\n",
            "Successfully installed youtube_transcript_api-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3poocnU4kzya",
        "outputId": "22667510-a144-4247-9435-32514fd869e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.20.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Downloading groq-0.20.0-py3-none-any.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pinecone\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from groq import Groq\n",
        "import torch\n",
        "from typing import List, Dict, Any, Optional\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import spacy\n",
        "\n",
        "class EnhancedRAGSystem:\n",
        "    def __init__(self, pinecone_api_key: str, groq_api_key: str, index_name: str,\n",
        "                 model_name: str = \"sentence-transformers/all-mpnet-base-v2\"):\n",
        "        \"\"\"\n",
        "        Initialize Enhanced RAG system with Pinecone, Groq, and models.\n",
        "        \"\"\"\n",
        "        # Initialize Pinecone client\n",
        "        self.pc = pinecone.Pinecone(api_key=pinecone_api_key)\n",
        "        self.index = self.pc.Index(index_name)\n",
        "\n",
        "        # Initialize Groq client\n",
        "        self.groq_client = Groq(api_key=groq_api_key)\n",
        "\n",
        "        # Check for GPU availability\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Initialize embedding model\n",
        "        self.embedding_model = SentenceTransformer(model_name).to(self.device)\n",
        "\n",
        "        # Set parameters\n",
        "        self.top_k = 1  # Retrieve only the top source\n",
        "\n",
        "        # Initialize NLP tools with better error handling\n",
        "        try:\n",
        "            nltk.download('stopwords', quiet=True)\n",
        "            nltk.download('wordnet', quiet=True)\n",
        "            self.stop_words = set(stopwords.words('english'))\n",
        "            self.lemmatizer = WordNetLemmatizer()\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: NLTK resource download issue. Error: {e}\")\n",
        "            self.stop_words = {'a', 'an', 'the', 'and', 'or', 'but', 'is', 'are', 'was', 'were', 'to', 'of', 'in', 'for'}\n",
        "            self.lemmatizer = None\n",
        "\n",
        "        # Load spaCy model with fallback\n",
        "        try:\n",
        "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "        except:\n",
        "            print(\"Warning: spaCy model 'en_core_web_sm' not found. Using a simple pipeline.\")\n",
        "            self.nlp = spacy.blank(\"en\")\n",
        "\n",
        "    def generate_answer(self, query: str, relevant_chunks: List[Dict[str, Any]]) -> str:\n",
        "        \"\"\"\n",
        "        Generate a comprehensive answer using Groq's language model based on the query and relevant chunk.\n",
        "        \"\"\"\n",
        "        if not relevant_chunks:\n",
        "            return \"I couldn't find sufficient information to answer your question. Please try rephrasing or asking a different question.\"\n",
        "\n",
        "        # Use the top (most relevant) chunk\n",
        "        top_chunk = relevant_chunks[0]\n",
        "        context = top_chunk['text']\n",
        "\n",
        "        # Prepare a focused prompt for the Groq language model\n",
        "        prompt = f\"\"\"\n",
        "        You are an intelligent assistant specialized in educational content. Your task is to create a comprehensive, well-structured answer to the user's question using the provided context.\n",
        "\n",
        "        USER QUESTION:\n",
        "        {query}\n",
        "\n",
        "        RELEVANT CONTEXT:\n",
        "        {context}\n",
        "        \"\"\"\n",
        "\n",
        "        # Use Groq's chat completion API\n",
        "        try:\n",
        "            response = self.groq_client.chat.completions.create(\n",
        "                model=\"llama3-70b-8192\",  # You can change this to other available Groq models\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are an intelligent assistant specialized in educational content.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                max_tokens=512,\n",
        "                temperature=0.7,\n",
        "                top_p=0.95\n",
        "            )\n",
        "\n",
        "            # Extract the answer from the response\n",
        "            answer = response.choices[0].message.content.strip()\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating answer with Groq: {e}\")\n",
        "            return \"I encountered an error while generating the answer. Please try again.\"\n",
        "\n",
        "    # Rest of the methods remain the same as in the original code\n",
        "    def extract_transcript(self, video_id: str) -> Optional[str]:\n",
        "        \"\"\"\n",
        "        Extract transcript from a YouTube video.\n",
        "\n",
        "        Args:\n",
        "            video_id: YouTube video ID\n",
        "\n",
        "        Returns:\n",
        "            Transcript text or None if extraction fails\n",
        "        \"\"\"\n",
        "        if not video_id or not isinstance(video_id, str):\n",
        "            print(\"Invalid video ID provided\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            transcript_list = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "            if not transcript_list:\n",
        "                print(f\"No transcript found for video {video_id}\")\n",
        "                return None\n",
        "\n",
        "            # Ensure proper formatting with punctuation\n",
        "            formatted_segments = []\n",
        "            for segment in transcript_list:\n",
        "                text = segment.get('text', '').strip()\n",
        "                if text:\n",
        "                    # Add period if segment doesn't end with punctuation\n",
        "                    if not text[-1] in ['.', '!', '?', ':', ';']:\n",
        "                        text += '.'\n",
        "                    formatted_segments.append(text)\n",
        "\n",
        "            full_transcript = ' '.join(formatted_segments)\n",
        "            return full_transcript\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching transcript for video {video_id}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def simple_tokenize(self, text):\n",
        "        \"\"\"Simple tokenizer that avoids NLTK's punkt.\"\"\"\n",
        "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "        return [token for token in text.lower().split() if token]\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"NLP preprocessing: stopword removal, lemmatization.\"\"\"\n",
        "        if not text or not isinstance(text, str):\n",
        "            return \"\", {}\n",
        "\n",
        "        text = re.sub(r'[^\\w\\s]', ' ', text).lower()\n",
        "        tokens = self.simple_tokenize(text)\n",
        "        filtered_tokens = [word for word in tokens if word not in self.stop_words]\n",
        "\n",
        "        # Use lemmatizer if available\n",
        "        if self.lemmatizer:\n",
        "            lemmatized_tokens = [self.lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "        else:\n",
        "            lemmatized_tokens = filtered_tokens\n",
        "\n",
        "        processed_text = ' '.join(lemmatized_tokens)\n",
        "        return processed_text, {}\n",
        "\n",
        "    def embed_query(self, query: str) -> List[float]:\n",
        "        \"\"\"Generate embedding for the query.\"\"\"\n",
        "        if not query or not isinstance(query, str):\n",
        "            print(\"Warning: Empty or invalid query received for embedding\")\n",
        "            return [0.0] * self.embedding_model.get_sentence_embedding_dimension()\n",
        "\n",
        "        # Apply preprocessing\n",
        "        processed_query, _ = self.preprocess_text(query)\n",
        "\n",
        "        # Ensure we have text to embed\n",
        "        if not processed_query:\n",
        "            processed_query = query  # Fall back to original query\n",
        "\n",
        "        # Generate embedding\n",
        "        return self.embedding_model.encode(processed_query).tolist()\n",
        "\n",
        "    def retrieve_relevant_chunks(self, query_embedding: List[float], top_k: int = 1, video_id: Optional[str] = None) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Retrieve the most relevant chunk from Pinecone based on the query embedding.\n",
        "        Optionally filter by video ID.\n",
        "        \"\"\"\n",
        "        # Prepare query parameters\n",
        "        query_params = {\n",
        "            \"vector\": query_embedding,\n",
        "            \"top_k\": top_k,\n",
        "            \"include_metadata\": True\n",
        "        }\n",
        "\n",
        "        # Add video ID filter if provided\n",
        "        if video_id:\n",
        "            query_params[\"filter\"] = {\"video_id\": video_id}\n",
        "\n",
        "        # Query Pinecone index using similarity search\n",
        "        try:\n",
        "            query_response = self.index.query(**query_params)\n",
        "        except Exception as e:\n",
        "            print(f\"Error querying Pinecone: {e}\")\n",
        "            return []\n",
        "\n",
        "        # Extract matches with their metadata\n",
        "        matches = query_response.get('matches', [])\n",
        "\n",
        "        # Format results\n",
        "        results = []\n",
        "        for match in matches:\n",
        "            # Extract text sample from metadata if available\n",
        "            text = match.metadata.get('text_sample', 'No text available')\n",
        "\n",
        "            # Format the result\n",
        "            result = {\n",
        "                'id': match.id,\n",
        "                'score': match.score,\n",
        "                'text': text,\n",
        "                'video_id': match.metadata.get('video_id', 'unknown'),\n",
        "                'chunk_id': match.metadata.get('chunk_id', -1)\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def query(self, question: str, video_id: Optional[str] = None) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Process a user query and return a well-structured answer with supporting evidence.\n",
        "\n",
        "        Args:\n",
        "            question: The user's question\n",
        "            video_id: Optional YouTube video ID to filter sources\n",
        "        \"\"\"\n",
        "        # Step 1: Generate embedding for the question\n",
        "        query_embedding = self.embed_query(question)\n",
        "\n",
        "        # Step 2: Retrieve the most relevant chunk from Pinecone, optionally filtered by video ID\n",
        "        relevant_chunks = self.retrieve_relevant_chunks(\n",
        "            query_embedding,\n",
        "            self.top_k,\n",
        "            video_id\n",
        "        )\n",
        "\n",
        "        # If no chunks found and a video ID was provided, try without the filter\n",
        "        if not relevant_chunks and video_id:\n",
        "            relevant_chunks = self.retrieve_relevant_chunks(query_embedding, self.top_k)\n",
        "\n",
        "        # Step 3: Generate a comprehensive answer based on the retrieved chunk\n",
        "        answer = self.generate_answer(question, relevant_chunks)\n",
        "\n",
        "        # Step 4: Try to fetch video transcript if a video ID was provided and no relevant chunks found\n",
        "        video_transcript = None\n",
        "        if video_id and not relevant_chunks:\n",
        "            video_transcript = self.extract_transcript(video_id)\n",
        "\n",
        "        # Step 5: Return the answer and top source\n",
        "        result = {\n",
        "            \"question\": question,\n",
        "            \"answer\": answer,\n",
        "            \"source\": relevant_chunks[0] if relevant_chunks else None,\n",
        "            \"video_id\": video_id,\n",
        "            \"video_transcript\": video_transcript\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    def format_response(self, result: Dict[str, Any]) -> str:\n",
        "        \"\"\"\n",
        "        Format the query result into a well-structured response string.\n",
        "        \"\"\"\n",
        "        response = f\"QUESTION: {result['question']}\\n\\nANSWER:\\n{result['answer']}\\n\\n\"\n",
        "\n",
        "        if result.get('source'):\n",
        "            source = result['source']\n",
        "            response += \"TOP SOURCE:\\n\"\n",
        "            response += f\"Score: {source['score']:.2f}\\n\"\n",
        "            response += f\"Text: {source['text']}\\n\"\n",
        "\n",
        "        # Add video transcript if available\n",
        "        if result.get('video_transcript'):\n",
        "            response += \"\\nVIDEO TRANSCRIPT EXCERPT:\\n\"\n",
        "            # Limit transcript to first 500 characters\n",
        "            transcript_excerpt = result['video_transcript'][:500] + \"...\"\n",
        "            response += transcript_excerpt + \"\\n\"\n",
        "\n",
        "        return response\n",
        "\n",
        "\n",
        "# Example usage\n",
        "def main():\n",
        "    # Initialize the RAG system\n",
        "    pinecone_api_key = \"pcsk_7EKroD_MaZi2zjikyZTdpaDPCkit4qEAE6cjKuJ7C2ot9htS7EE6uurWQLrfznykMd7bW3\"\n",
        "    groq_api_key = \"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\"\n",
        "    index_name = \"embeddings\"\n",
        "\n",
        "    print(\"Initializing Enhanced RAG system...\")\n",
        "    rag = EnhancedRAGSystem(\n",
        "        pinecone_api_key=pinecone_api_key,\n",
        "        groq_api_key=groq_api_key,\n",
        "        index_name=index_name,\n",
        "        model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
        "    )\n",
        "\n",
        "    # Example query with video ID\n",
        "    question = \"What is JVM?\"\n",
        "    video_id = \"NUy_wOxOM8E\"  # Example YouTube video ID\n",
        "\n",
        "    # Add error handling around the main query operation\n",
        "    try:\n",
        "        print(f\"Processing query: '{question}' with video ID: {video_id}\")\n",
        "        result = rag.query(question, video_id)\n",
        "\n",
        "        # Format and print the result\n",
        "        formatted_response = rag.format_response(result)\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(formatted_response)\n",
        "        print(\"=\"*50)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during query processing: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "w7EYfF3PMOS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "640e5d9f-6b63-4838-e3ea-ad66daf05c1c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Enhanced RAG system...\n",
            "Using device: cpu\n",
            "Processing query: 'What is JVM?' with video ID: NUy_wOxOM8E\n",
            "\n",
            "==================================================\n",
            "QUESTION: What is JVM?\n",
            "\n",
            "ANSWER:\n",
            "**What is JVM (Java Virtual Machine)?**\n",
            "\n",
            "As we embark on our journey to master Java, it's essential to establish a solid foundation in Java terminology. One of the critical concepts to grasp is the Java Virtual Machine, commonly referred to as JVM.\n",
            "\n",
            "**Definition:**\n",
            "The Java Virtual Machine (JVM) is a virtual machine that runs Java bytecode on a computer. It's the runtime environment for Java, responsible for executing Java programs.\n",
            "\n",
            "**How it works:**\n",
            "When you compile a Java program, the Java compiler (javac) converts the Java source code (.java files) into an intermediate format called bytecode (.class files). This bytecode is platform-independent, meaning it can run on any device supporting a JVM, regardless of the underlying operating system or hardware architecture.\n",
            "\n",
            "The JVM interprets and executes the bytecode, providing a layer of abstraction between the Java code and the underlying machine. This abstraction enables Java's \"write once, run anywhere\" philosophy, allowing Java programs to be platform-agnostic and highly portable.\n",
            "\n",
            "**Key Features:**\n",
            "\n",
            "1. **Platform Independence**: JVM enables Java code to run on any platform that has a JVM, without the need for recompilation.\n",
            "2. **Memory Management**: JVM manages memory allocation and deallocation for Java programs, freeing developers from worrying about memory-related issues.\n",
            "3. **Security**: JVM provides a sandboxed environment for Java code, ensuring that it runs in a secure and controlled manner.\n",
            "4. **Dynamic Loading of Classes**: JVM can dynamically load classes as needed, reducing the memory footprint of Java programs.\n",
            "\n",
            "**In summary**, the JVM is a crucial component of the Java ecosystem, providing a runtime environment for Java programs to execute. Its platform independence, memory management, security features, and dynamic class loading make it an essential element in the development and deployment of Java applications.\n",
            "\n",
            "Now that we've established a solid understanding of JVM, we can move forward with confidence, exploring more advanced Java concepts, such as methods, classes, and others.\n",
            "\n",
            "TOP SOURCE:\n",
            "Score: 0.56\n",
            "Text: hello I'm Jason with code learner calm welcome to mastering Java here we're going to talk about Java terminology we really need to build a foundation on some common terms because if I just jump right into writing code with you then I start talking about methods and classes and you know Java virtual machines and other things if you don't know what those things are then and you're just going to be confused and there's no reason for that because all of the java terminology that you need to know is ...\n",
            "\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Va_fKwkbwAjO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}